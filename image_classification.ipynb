{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8xk45YOEMbB",
        "outputId": "f80f7605-c449-483b-ecc3-974bc7b891f8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "DATA_PATH = r\".\\data\"\n",
        "MODEL_PATH = r\".\\models\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y0ygXc54hHHm"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_data_file_paths():\n",
        "    with open(rf\"{DATA_PATH}\\file_paths.csv\", \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"image\", \"mask\", \"label\"])\n",
        "        for sbj in range(100):\n",
        "            if os.path.exists(rf\"{DATA_PATH}\\0\\{sbj:02}\"):\n",
        "                label = 0\n",
        "            elif os.path.exists(rf\"{DATA_PATH}\\1\\{sbj:02}\"):\n",
        "                label = 1\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            writer.writerow(\n",
        "                [\n",
        "                    rf\"{sbj:02}\\CT_partition.npy\",\n",
        "                    rf\"{sbj:02}\\CT_mask.npy\",\n",
        "                    label,\n",
        "                ]\n",
        "            )\n",
        "\n",
        "\n",
        "write_data_file_paths()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKwHAoAYAgfK"
      },
      "outputs": [],
      "source": [
        "def load_haralick_features():\n",
        "    try:\n",
        "        data = pd.read_csv(rf\"{DATA_PATH}\\haralick.csv\", index_col=0)\n",
        "        labels = data.pop(\"y\")\n",
        "        return data, labels\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found, generating...\")\n",
        "        data, labels = [], []\n",
        "\n",
        "        with open(rf\"{DATA_PATH}\\file_paths.csv\", \"r\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)\n",
        "            for image_path, mask_path, _ in reader:\n",
        "                image = np.load(rf\"{DATA_PATH}\\{image_path}\")\n",
        "                mask = np.load(rf\"{DATA_PATH}\\{mask_path}\")\n",
        "                ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtUMGnGvjljB"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE4uUrHIuV6w"
      },
      "outputs": [],
      "source": [
        "def print_metrics(y_true, y_pred, model_name) -> None:\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(model_name)\n",
        "    print(f\"Sensitivity: {tp / (tp + fn) * 100:.1f}%\")\n",
        "    print(f\"Specificity: {tn / (tn + fp) * 100:.1f}%\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred) * 100:.1f}%\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_true, y_pred) * 100:.1f}%\")\n",
        "\n",
        "    plt.imshow(cm, cmap=mpl.colormaps[\"Blues\"])\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"{model_name} Confusion matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xticks([0, 1], [\"BENIGN\", \"MALIGNANT\"])\n",
        "    plt.yticks([0, 1], [\"BENIGN\", \"MALIGNANT\"])\n",
        "    for (j, i), label in np.ndenumerate(cm):\n",
        "        color = \"darkblue\" if label < cm.max() / 2 else \"white\"\n",
        "        plt.text(i, j, label, color=color)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    *load_haralick_features(), test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "svc_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        # (\"pca\", PCA(0.9)),\n",
        "        (\"svc\", SVC(kernel=\"linear\", random_state=SEED)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "rf_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        # (\"pca\", PCA(0.9)),\n",
        "        (\"rf\", RandomForestClassifier(criterion=\"entropy\", random_state=SEED)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "ElFtBgwGqen7",
        "outputId": "27779fce-c390-4773-cdaf-74f1cf9bf289"
      },
      "outputs": [],
      "source": [
        "svc_pipe.fit(X_train, y_train)\n",
        "y_pred = svc_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Linear SVC\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kzfn2RFvDbC",
        "outputId": "5b70b773-847a-4248-f46f-8d761773420f"
      },
      "outputs": [],
      "source": [
        "rf_pipe.fit(X_train, y_train)\n",
        "y_pred = rf_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Random Forest\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from data import CTData\n",
        "from unet import UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_DEPTH = 16\n",
        "IMAGE_SIZE = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_rois():\n",
        "    with open(rf\"{DATA_PATH}\\file_paths.csv\", \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)\n",
        "        \n",
        "        for image, mask, label in reader:\n",
        "\n",
        "            ct_scan = np.load(rf\"{DATA_PATH}\\{label}\\{image}\")\n",
        "            ct_mask = np.load(rf\"{DATA_PATH}\\{label}\\{mask}\")\n",
        "\n",
        "            roi = np.unique(np.where(ct_mask == 1), axis=1)\n",
        "            roi_cx, roi_cy, roi_cz = (roi.max(axis=1) + roi.min(axis=1)) // 2\n",
        "            bounding_box = ct_mask[\n",
        "                roi_cx - IMAGE_DEPTH // 2 : roi_cx + IMAGE_DEPTH // 2,\n",
        "                roi_cy - IMAGE_SIZE // 2 : roi_cy + IMAGE_SIZE // 2,\n",
        "                roi_cz - IMAGE_SIZE // 2 : roi_cz + IMAGE_SIZE // 2,\n",
        "            ]\n",
        "            image_out = ct_scan[\n",
        "                roi_cx - IMAGE_DEPTH // 2 : roi_cx + IMAGE_DEPTH // 2,\n",
        "                roi_cy - IMAGE_SIZE // 2 : roi_cy + IMAGE_SIZE // 2,\n",
        "                roi_cz - IMAGE_SIZE // 2 : roi_cz + IMAGE_SIZE // 2,\n",
        "            ]\n",
        "\n",
        "            os.mkdir(rf\"{DATA_PATH}\\rois\\{image[:2]}\")\n",
        "            np.save(rf\"{DATA_PATH}\\rois\\{image}\", image_out)\n",
        "            np.save(rf\"{DATA_PATH}\\rois\\{mask}\", bounding_box)\n",
        "\n",
        "\n",
        "save_rois()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, masks, labels = [], [], []\n",
        "with open(rf\"{DATA_PATH}\\file_paths.csv\", \"r\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "\n",
        "    for image, mask, label in reader:\n",
        "        images.append(np.load(rf\"{DATA_PATH}\\rois\\{image}\"))\n",
        "        masks.append(np.load(rf\"{DATA_PATH}\\rois\\{mask}\"))\n",
        "        labels.append(int(label))\n",
        "\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images, test_images, train_masks, test_masks, y_train, y_test = train_test_split(\n",
        "    images, masks, labels, test_size=0.2, random_state=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(train_images, train_masks), BATCH_SIZE, shuffle=True\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(test_images, test_masks), 1, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def threshold(data: torch.Tensor, level: float = 0.5) -> torch.Tensor:\n",
        "    scaled = (data - data.min()) / (data.max() - data.min())\n",
        "    scaled[scaled < level] = 0\n",
        "    scaled[scaled >= level] = 1\n",
        "    return scaled.type(torch.int32)\n",
        "\n",
        "\n",
        "def pixel_accuracy(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sum(pred == true) / np.prod(pred.shape)\n",
        "\n",
        "\n",
        "def iou(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    intersection = torch.logical_and(true, pred)\n",
        "    union = torch.logical_or(true, pred)\n",
        "    return torch.sum(intersection) / torch.sum(union)\n",
        "\n",
        "\n",
        "def dice_coeff(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    intersection = torch.logical_and(true, pred)\n",
        "    return 2 * torch.sum(intersection) / (torch.sum(true) + torch.sum(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNet(residual=False, cat=False)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = torch.nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_loss, iou_loss, dice_loss = [], [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for image, ct_mask in train_dataloader:\n",
        "        image = image.to(device)\n",
        "        ct_mask = ct_mask.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # pred = threshold(model(image))\n",
        "        pred = model(image)\n",
        "        loss = loss_fn(pred, ct_mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 49:\n",
        "        model.eval()\n",
        "        model.cpu()\n",
        "        epoch_pixel_loss, epoch_iou_loss, epoch_dice_loss = [], [], []\n",
        "        for image, ct_mask in test_dataloader:\n",
        "            # image = image.to(device)\n",
        "            # mask = mask.to(device)\n",
        "            pred = threshold(model(image))\n",
        "\n",
        "            pixel = pixel_accuracy(pred, ct_mask)\n",
        "            jaccard = iou(pred, ct_mask)\n",
        "            dice = dice_coeff(pred, ct_mask).detach()\n",
        "\n",
        "            epoch_pixel_loss.append(pixel)\n",
        "            epoch_iou_loss.append(jaccard)\n",
        "            epoch_dice_loss.append(dice)\n",
        "\n",
        "        mean_pixel_loss = np.mean(epoch_pixel_loss)\n",
        "        mean_iou_loss = np.mean(epoch_iou_loss)\n",
        "        mean_dice_loss = np.mean(epoch_dice_loss)\n",
        "        \n",
        "        pixel_loss.append(mean_pixel_loss)\n",
        "        iou_loss.append(mean_iou_loss)\n",
        "        dice_loss.append(mean_dice_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} / {EPOCHS} metrics:\")\n",
        "        print(f\"PA {mean_pixel_loss:.4f} | IoU {mean_iou_loss:.4f} | Dice {mean_dice_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), rf\"{MODEL_PATH}\\unet_l1_2000.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.arange(50, EPOCHS + 1, 50)\n",
        "plt.plot(x, pixel_loss, label=\"PA\")\n",
        "plt.plot(x, iou_loss, label=\"IoU\")\n",
        "plt.plot(x, dice_loss, label=\"Dice\")\n",
        "plt.legend()\n",
        "plt.title(\"Test performance by epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.cpu()\n",
        "iter_data = iter(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image, ct_mask = next(iter_data)\n",
        "pred = threshold(model(image), 0.75)\n",
        "\n",
        "print(f\"Pixel accuracy: {pixel_accuracy(pred, ct_mask):.4f}\")\n",
        "print(f\"IOU (Jaccard): {iou(pred, ct_mask):.4f}\")\n",
        "print(f\"Dice coefficient (F1-score): {dice_coeff(pred, ct_mask):.4f}\")\n",
        "\n",
        "image = image.cpu().detach().numpy()\n",
        "pred = pred.cpu().detach().numpy()\n",
        "ct_mask = ct_mask.cpu().detach().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(4, 12)\n",
        "for slc in range(16):\n",
        "    r, c = divmod(slc, 4)\n",
        "\n",
        "    ax[r, c].imshow(image[0, 0, slc, :, :])\n",
        "    ax[r, c + 4].imshow(pred[0, 0, slc, :, :])\n",
        "    ax[r, c + 8].imshow(ct_mask[0, 0, slc, :, :])\n",
        "\n",
        "    ax[r, c].axis(\"off\")\n",
        "    ax[r, c + 4].axis(\"off\")\n",
        "    ax[r, c + 8].axis(\"off\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import radiomics\n",
        "import SimpleITK as sitk\n",
        "from radiomics import featureextractor\n",
        "\n",
        "radiomics.setVerbosity(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_haralick_features(image: np.ndarray, mask: np.ndarray) -> np.ndarray:\n",
        "    img = sitk.GetImageFromArray(image)\n",
        "    msk = sitk.GetImageFromArray(mask)\n",
        "    \n",
        "    extractor = featureextractor.RadiomicsFeatureExtractor()\n",
        "    extractor.disableAllFeatures()\n",
        "    extractor.enableFeatureClassByName(\"glcm\")\n",
        "    result = extractor.execute(img, msk)\n",
        "    return np.array([value for key, value in result.items() if \"glcm\" in key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(images, masks), 1, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNet(residual=False, cat=False)\n",
        "model.load_state_dict(torch.load(rf\"{MODEL_PATH}\\unet_final.pt\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = []\n",
        "for image, _ in full_dataloader:\n",
        "    ct_mask = threshold(model(image)).detach().numpy()\n",
        "    image = image.detach().numpy()\n",
        "    features.append(get_haralick_features(image[0, 0], ct_mask[0, 0]))\n",
        "features = np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.2, random_state=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc_pipe.fit(X_train, y_train)\n",
        "y_pred = svc_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Linear SVC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(svc_pipe, rf\"{MODEL_PATH}\\svc.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = np.load(rf\"{DATA_PATH}\\0\\01\\CT_partition.npy\")\n",
        "mask = np.load(rf\"{DATA_PATH}\\0\\01\\CT_mask.npy\")\n",
        "roi = np.unique(np.where(mask == 1), axis=1)\n",
        "center, *_ = (roi.max(axis=1) + roi.min(axis=1)) // 2\n",
        "center -= 8\n",
        "print(center)\n",
        "\n",
        "fig, ax = plt.subplots(4, 8)\n",
        "for slc in range(16):\n",
        "    r, c = divmod(slc, 4)\n",
        "\n",
        "    ax[r, c].imshow(image[slc + center])\n",
        "    ax[r, c + 4].imshow(mask[slc + center])\n",
        "\n",
        "    ax[r, c].axis(\"off\")\n",
        "    ax[r, c + 4].axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
